
# enable stemming of words in the content
enable_stemming: true

# filtering the feature vectors

# keep/drop numbers from the contents
filter_numbers: true

# filtering feature vector of each doc
# a value of <=1 will include all words
filter_words_less_than: 4

# just retain top-k words in feature vector 
# based on tf-idf ranking
# any value less than 0 will retain all words
# NOTE: In transaction data format top k words of
# each document will be retained. In data matrix format
# top k words of the corpus will be retained.
retain_top_k_words: 512

# all output files/folders will be written to this location
output_dir: "./output"

# type of classifier to use. currently supports only knn
classifier: "knn"

# if split is "unknown", then all the tuples whose topics are
# "unknown" will be used as testing set
# other possible values can be number between 0 to 100 or
# set of numbers between 0 to 100.
# Example: if split: [70, 80] then there will be two directories
# for training set output_dir/knn/training/70, output_dir/knn/training/80
# and two directories for testing output_dir/knn/testing/30, output_dir/knn/testing/20
# These files are stored are csv file and hence required further processing
# if used with other tools.
split: "unknown"

enable_classifier: false

# used for hierarchical clustering where only a sample set of feature vector is required
sample: 0.2
seed: 10